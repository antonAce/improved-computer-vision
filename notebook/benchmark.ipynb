{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hd39vLQ4ily"
      },
      "source": [
        "# Overview of existing gradient algorithms\n",
        "\n",
        "In this assignment, we explore the evolution and significance of gradient descent algorithms, focusing on their applications in handling complex data-driven problems prevalent in fields such as machine learning and natural language processing. We will delve into the foundations of both classical and adaptive stochastic gradient techniques and investigating their convergence properties.\n",
        "\n",
        "### Historical Context\n",
        "\n",
        "Gradient descent algorithms have evolved significantly, starting from the stochastic approximation methods of Kiefer-Wolfowitz and Robbins-Monro in the 1950s, to the introduction of advanced techniques like Momentum Gradient Descent and Nesterov's accelerated method in the 1980s. The 2010s marked a shift towards adaptive methods, with algorithms like AdaGrad, RMSProp, and ADAM, each bringing unique approaches to learning rate adjustments and showcasing effectiveness in various applications, particularly in deep learning.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "1. Understand the fundamental concepts of gradient, gradient descent, and stochastic optimization;\n",
        "2. Explore the theoretical foundations and practical applications of various stochastic gradient descent algorithms;\n",
        "3. Compare the performance of different gradient descent algorithms on a test convex and smooth objective function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_quN7U1T9aH"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before delving into the implementation and comparison of gradient descent algorithms, it is essential to set up the necessary computational environment. We will be utilizing the PyTorch library to perform all calculations, as it offers a flexible and efficient platform for scientific computing, particularly in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3jT6dGjUdf9",
        "outputId": "082950ed-c9c9-4c38-dc5a-1d0b4f7dd834"
      },
      "outputs": [],
      "source": [
        "# Import the PyTorch library\n",
        "import torch\n",
        "\n",
        "# Check the version of PyTorch\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "\n",
        "# Perform a basic operation to test PyTorch\n",
        "a = torch.tensor([1.0, 2.0])\n",
        "b = torch.tensor([3.0, 4.0])\n",
        "\n",
        "# Assert the result of the sum\n",
        "assert torch.equal(a + b, torch.tensor([4.0, 6.0])), \"The sum of a and b is incorrect!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zW8YIIsU4Fs"
      },
      "source": [
        "## Stochastic Optimization Problem\n",
        "\n",
        "Stochastic optimization problems form the bedrock for addressing uncertainties and randomness inherent in various domains like finance, machine learning, and operations research. Contrasting with deterministic optimization, where the objective function and constraints are well-defined, stochastic optimization introduces challenges by incorporating components that exhibit randomness. In this section, we delve into the mathematical formulation of a stochastic optimization problem and explore how stochastic gradient descent algorithms tackle the challenges presented by this formulation.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "Given an objective function $ f: X \\to \\mathbb{R} ^ n $ with domain $ X \\subset \\mathbb{R} ^ n $, and a convex and differentiable function $ F: X \\times \\Xi \\to \\mathbb{R} ^ 1 $ that depends on the determined variable $ x \\in X $ and a stochastic variable $ \\xi \\in \\Xi $, defined on a space $ (\\Xi, \\Sigma, P) $, a stochastic optimization problem can be represented as:\n",
        "\n",
        "$$\n",
        "\\min_{x \\in X} \\left[f(x) = \\mathbb{E} F(x, \\xi) = \\int_{\\xi \\in \\Xi} F(x, \\xi) P(d \\xi), X \\subset \\mathbb{R} ^ n\\right]\n",
        "$$\n",
        "\n",
        "Here, $ \\mathbb{E} $ denotes the mathematical expectation. The intrinsic challenge of this problem lies in the difficulty of explicitly calculating the value of an integral (mathematical expectation) and the gradient of this integral. Stochastic gradient descent algorithms, leveraging gradients $ \\nabla_{x} F(x, \\xi) $ of a stochastic function $ F(\\cdot, \\xi) $ or their finite-difference counterparts, offer a solution to this challenge.\n",
        "\n",
        "### Practical Implications\n",
        "\n",
        "These optimization problems are pivotal in scenarios where decision-making is dependent on incomplete or uncertain information. Employing techniques such as random sampling, Monte Carlo simulations, and stochastic gradients, stochastic optimization methods effectively and efficiently traverse the optimization landscape, aiming for convergence to the optimal solution."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
