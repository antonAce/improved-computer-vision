{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hd39vLQ4ily"
      },
      "source": [
        "# Introduction and Overview of existing gradient algorithms\n",
        "\n",
        "In this assignment, we explore the evolution and significance of gradient descent algorithms, focusing on their applications in handling complex data-driven problems prevalent in fields such as machine learning and natural language processing. We will delve into the foundations of both classical and adaptive stochastic gradient techniques and investigating their convergence properties.\n",
        "\n",
        "### Historical Context\n",
        "\n",
        "Gradient descent algorithms have evolved significantly, starting from the stochastic approximation methods of Kiefer-Wolfowitz and Robbins-Monro in the 1950s, to the introduction of advanced techniques like Momentum Gradient Descent and Nesterov's accelerated method in the 1980s. The 2010s marked a shift towards adaptive methods, with algorithms like AdaGrad, RMSProp, and ADAM, each bringing unique approaches to learning rate adjustments and showcasing effectiveness in various applications, particularly in deep learning.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "1. Understand the fundamental concepts of gradient, gradient descent, and stochastic optimization;\n",
        "2. Explore the theoretical foundations and practical applications of various stochastic gradient descent algorithms;\n",
        "3. Compare the performance of different gradient descent algorithms on a test convex and smooth objective function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_quN7U1T9aH"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before delving into the implementation and comparison of gradient descent algorithms, it is essential to set up the necessary computational environment. We will be utilizing the PyTorch library to perform all calculations, as it offers a flexible and efficient platform for scientific computing, particularly in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3jT6dGjUdf9",
        "outputId": "9423c8b0-aae6-4c4f-f39c-8f99d1530fae"
      },
      "outputs": [],
      "source": [
        "# Import the PyTorch library\n",
        "import torch\n",
        "\n",
        "# Import typing annotations for assignment hints\n",
        "from typing import Callable\n",
        "\n",
        "# Check the version of PyTorch\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "\n",
        "# Perform a basic operation to test PyTorch\n",
        "a = torch.tensor([1.0, 2.0])\n",
        "b = torch.tensor([3.0, 4.0])\n",
        "\n",
        "# Assert the result of the sum\n",
        "assert torch.equal(a + b, torch.tensor([4.0, 6.0])), \"The sum of a and b is incorrect!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zW8YIIsU4Fs"
      },
      "source": [
        "## Stochastic Optimization Problem\n",
        "\n",
        "Stochastic optimization problems form the bedrock for addressing uncertainties and randomness inherent in various domains like finance, machine learning, and operations research. Contrasting with deterministic optimization, where the objective function and constraints are well-defined, stochastic optimization introduces challenges by incorporating components that exhibit randomness. In this section, we delve into the mathematical formulation of a stochastic optimization problem and explore how stochastic gradient descent algorithms tackle the challenges presented by this formulation.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "Given an objective function $ f: X \\to \\mathbb{R} ^ n $ with domain $ X \\subset \\mathbb{R} ^ n $, and a convex and differentiable function $ F: X \\times \\Xi \\to \\mathbb{R} ^ 1 $ that depends on the determined variable $ x \\in X $ and a stochastic variable $ \\xi \\in \\Xi $, defined on a space $ (\\Xi, \\Sigma, P) $, a stochastic optimization problem can be represented as:\n",
        "\n",
        "$$\n",
        "\\min_{x \\in X} \\left[f(x) = \\mathbb{E} F(x, \\xi) = \\int_{\\xi \\in \\Xi} F(x, \\xi) P(d \\xi), X \\subset \\mathbb{R} ^ n\\right]\n",
        "$$\n",
        "\n",
        "Here, $ \\mathbb{E} $ denotes the mathematical expectation. The intrinsic challenge of this problem lies in the difficulty of explicitly calculating the value of an integral (mathematical expectation) and the gradient of this integral. Stochastic gradient descent algorithms, leveraging gradients $ \\nabla_{x} F(x, \\xi) $ of a stochastic function $ F(\\cdot, \\xi) $ or their finite-difference counterparts, offer a solution to this challenge.\n",
        "\n",
        "### Practical Implications\n",
        "\n",
        "These optimization problems are pivotal in scenarios where decision-making is dependent on incomplete or uncertain information. Employing techniques such as random sampling, Monte Carlo simulations, and stochastic gradients, stochastic optimization methods effectively and efficiently traverse the optimization landscape, aiming for convergence to the optimal solution.\n",
        "\n",
        "### Gradient approximation\n",
        "\n",
        "While libraries like PyTorch offer automatic differentiation, this assignment encourages a hands-on approach. We will be utilizing the second-order accurate central differences method to estimate gradients, offering insight into the intricacies of gradient computation and its role in optimization algorithms.\n",
        "\n",
        "We can derive approximation formula from the Taylor's series polynomial while discarding unnecessary residual terms that have higher accuracy order than the first order:\n",
        "\n",
        "$$ f(x_0 + h) = f(x_0) + f'(x_0)(h) + o(h) $$\n",
        "\n",
        "By applying finite differences approximation we get left and right finite differences:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "  f'_{-}(x) = \\frac{f(x + h) - f(x)}{h} - \\frac{h f''(\\xi)}{2} \\\\\n",
        "  f'_{+}(x) = \\frac{f(x) - f(x - h)}{h} + \\frac{h f''(\\xi)}{2}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The accuracy of the approximation depends on the number of nodes on the numerical partitioning grid, thus the smaller step difference, the higher precision. Using the Runge-Romberg-Richardson algorithm we can achieve an increase in the order of the precision of the partitioning grid up to $ O(h^2) $ without adding extra iterations to the approximation algorithm:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "  f'_{-}(x) = \\frac{-3 f(x) + 4 f(x + h) - f(x + 2h)}{2h} + \\frac{h^2 f'''(\\xi)}{3} \\\\\n",
        "  f'(x) = \\frac{f(x + h) - f(x - h)}{2h} + \\frac{h^2 f'''(\\xi)}{6} \\\\\n",
        "  f'_{+}(x) = \\frac{f(x - 2h) - 4 f(x - h) + 3 f(x)}{2h} + \\frac{h^2 f'''(\\xi)}{3}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The approach of approximating the gradient value of the target function with a finite-difference schema lets us generalize optimization problems on any kind of analytical functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hT1IpXQkA9W"
      },
      "outputs": [],
      "source": [
        "def grad_left(F: Callable[[torch.Tensor], torch.Tensor], x: torch.Tensor, h: float = 0.001) -> torch.Tensor:\n",
        "  \"\"\"A finite-difference approximation for left-side gradient ∇F₋(x) with the precision order O(h^2).\n",
        "\n",
        "  Args:\n",
        "      F (Callable[[torch.Tensor], torch.Tensor]): an objective function F(x) with a single input argument x ∈ ℝⁿ.\n",
        "      x (torch.Tensor): an input vector x ∈ ℝⁿ, where the derivative is calculated.\n",
        "      h (float, optional): a step of the derivative partitioning grid with the range of 0<h<1. The lower value, the higher gradient precision. Defaults to 0.001.\n",
        "\n",
        "  Returns:\n",
        "      torch.Tensor: a gradient vector approximation ∇F₋(x).\n",
        "  \"\"\"\n",
        "\n",
        "  pass # TODO: Implement second-order accurate forward difference algorithm\n",
        "\n",
        "\n",
        "def grad_center(F: Callable[[torch.Tensor], torch.Tensor], x: torch.Tensor, h: float = 0.001) -> torch.Tensor:\n",
        "  \"\"\"A finite-difference approximation for central gradient ∇F(x) with the precision order O(h^2).\n",
        "\n",
        "  Args:\n",
        "      F (Callable[[torch.Tensor], torch.Tensor]): a target function F(x) with a single input argument x ∈ ℝⁿ.\n",
        "      x (torch.Tensor): an input vector x ∈ ℝⁿ, where the derivative is calculated.\n",
        "      h (float, optional): a step of the derivative partitioning grid with the range of 0 < h < 1. The lower value, the higher gradient precision. Defaults to 0.001.\n",
        "\n",
        "  Returns:\n",
        "      torch.Tensor: a gradient vector approximation ∇F(x).\n",
        "  \"\"\"\n",
        "\n",
        "  pass # TODO: Implement second-order accurate center difference algorithm\n",
        "\n",
        "\n",
        "def grad_right(F: Callable[[torch.Tensor], torch.Tensor], x: torch.Tensor, h: float = 0.001) -> torch.Tensor:\n",
        "  \"\"\"A finite-difference approximation for right-side gradient ∇F+(x) with the precision order O(h^2).\n",
        "\n",
        "  Args:\n",
        "      F (Callable[[torch.Tensor], torch.Tensor]): a target function F(x) with a single input argument x ∈ ℝⁿ.\n",
        "      x (torch.Tensor): an input vector x ∈ ℝⁿ, where the derivative is calculated.\n",
        "      h (float, optional): a step of the derivative partitioning grid with the range of 0<h<1. The lower value, the higher gradient precision. Defaults to 0.001.\n",
        "\n",
        "  Returns:\n",
        "      torch.Tensor: a gradient vector approximation ∇F+(x).\n",
        "  \"\"\"\n",
        "\n",
        "  pass # TODO: Implement second-order accurate center difference algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb2OyaXMp80i"
      },
      "source": [
        "We will check the accuracy of the implemented method on the test case:\n",
        "\n",
        "$ F(x, y) = x^2 + xy + y^2 \\implies \\begin{cases} \\frac{\\partial F(x, y)}{\\partial x} = 2x + y, \\frac{\\partial F(2.0, -1.0)}{\\partial x} = 3.0 \\\\ \\frac{\\partial F(x, y)}{\\partial y} = x + 2y, \\frac{\\partial F(2.0, -1.0)}{\\partial y} = 0.0\n",
        " \\end{cases} $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k0BDMmqp7Ub"
      },
      "outputs": [],
      "source": [
        "h = 0.001\n",
        "x = torch.tensor([2.0, -1.0])\n",
        "f = lambda x: x[0] ** 2 + x[0] * x[1] + x[1] ** 2\n",
        "\n",
        "assert torch.allclose(grad_left(f, x, h=h), torch.tensor([3.0, 0.0]), rtol=h)\n",
        "assert torch.allclose(grad_center(f, x, h=h), torch.tensor([3.0, 0.0]), rtol=h)\n",
        "assert torch.allclose(grad_right(f, x, h=h), torch.tensor([3.0, 0.0]), rtol=h)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
